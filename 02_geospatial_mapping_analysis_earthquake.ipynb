{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project description:\n",
    "#### Goals of analysis\n",
    "* 1. Geospatial analysis of nepal earthquake data 2015\n",
    "* 2. Local Boundaries brings the detailed geodata of administrative units or maps of all administrative boundary defined by Nepal Government, in open and reusable format, free of cost. The local boundaries are available in two formats (TopoJSON and GeoJSON) and can be easily reused to map local authority data to OpenStreetMap, Google Map, Leaflet or MapBox interactively.The data of Local Boundaries are categorized in three different ways following the new federal structure, with 7 Provinces, 77 Districts, and 753 Local Levels. You can access the TopoJSON and GeoJSON files of all local levels, separately or in bulk according to your needs. http://localboundries.oknp.org/?fbclid=IwAR3Es1qk6DqarBO3vQERdfP7ntkS7Tp57kADlAueuuyb-EmLUJCMMMyLjIU\n",
    "* 3. The NHRP API requires one to provide a location_code. Tables below should help you with that, by providing location codes at a district and municipality level. Ward level codes are generated by appending the 2-digit ward number (padded with zeroes) to a municipality code (eg, Ward 2, Champadevi Rural Municipality is simply 1201 + 02 = 120102).\n",
    "http://eq2015.npc.gov.np/docs/?fbclid=IwAR2Bg_M2GRYCj_jkdbAOB-9Td-k40wsg0dchdS9Lm8TDv8_cHeK_vQM7oYs#/location_codes\n",
    "* 4. Understanding of shapefile https://gisgeography.com/arcgis-shapefile-files-types-extensions/\n",
    "* 5. scipy https://github.com/kjordahl/SciPy2013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pygeoj\n",
    "import json\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import *\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading files\n",
    "* combined clean data of building structure ownership\n",
    "* ward mapping district data \n",
    "* lat long data of all nepal districts - combined with ward-mapping files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BuildingPath      = \"input_data/building_damage_assessment_building_ownership_and_use_building_structure/\"\n",
    "data              = pd.read_csv('clean_data/building_structure_ownership.csv')\n",
    "ward_mapping_data = pd.read_csv(BuildingPath+'ward_vdcmun_district_name_mapping.csv')\n",
    "nepal_district    = pd.read_csv(BuildingPath+'nepal_district.csv')\n",
    "nepal_district.rename(columns = {'District':'district_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions\n",
    "\n",
    "* Functions to calculate distance from lat long. \n",
    "        The epicenter (latitude 28.24°N, longitude 84.75°E) of the earthquake was 77 kilometers northwest of Kathmandu at a depth of approximately 15 kilometers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "R = 6373.0\n",
    "\n",
    "#calculate distance\n",
    "def get_distance(x):\n",
    "    lat_epi = radians(28.24)\n",
    "    lon_epi = radians(84.75)\n",
    "    lat_d   = radians(x['lat'])\n",
    "    lon_d   = radians(x['long'])\n",
    "\n",
    "    dlon = lon_d - lon_epi\n",
    "    dlat = lat_d - lat_epi\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat_epi) * cos(lat_d) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    distance = R * c\n",
    "    return (distance)\n",
    "\n",
    "# calculate average distance\n",
    "def get_avg_distance(arr):\n",
    "    all_dist = []\n",
    "    if len(arr) == 1:\n",
    "        arr = arr[0]\n",
    "    for x in arr:\n",
    "        lat_epi = radians(28.24)\n",
    "        lon_epi = radians(84.75)\n",
    "        lat_d   = radians(x[1])\n",
    "        lon_d   = radians(x[0])\n",
    "\n",
    "        dlon = lon_d - lon_epi\n",
    "        dlat = lat_d - lat_epi\n",
    "\n",
    "        a = sin(dlat / 2)**2 + cos(lat_epi) * cos(lat_d) * sin(dlon / 2)**2\n",
    "        c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "        distance = R * c\n",
    "    all_dist.append(distance)\n",
    "    \n",
    "    return (np.mean(all_dist))\n",
    "\n",
    "#*ward:  chauri deurali *topo:  chaurideurali **ratio : 96\n",
    "#*ward:  sunkoshi *topo:  sukoshi **ratio : 93\n",
    "#*ward:  ganga jamuna *topo:  gangajamuna **ratio : 96\n",
    "#*ward:  shahid lakhan *topo:  sahid lakhan **ratio : 96\n",
    "#*ward:  siranchowk *topo:  siranchok **ratio : 95\n",
    "# *ward:  myagang *topo:  meghang **ratio : 71\n",
    "            \n",
    "def get_fuzzy_string(vdcnum):\n",
    "    fuzzy_low_ward = {'chumnuwri':'chumanubri','balefi':'balephi','meghang':'myagang','bhimsen': 'bhimsen thapa','indrawati':'indrawoti',\n",
    "                     'tamakoshi':'likhu tamakoshi', 'nilkantha':'neelakantha','melamchi': 'melanchi', 'indrasarawor': 'indrasarowar', \n",
    "                    'baiteshwor': 'baitedhar', 'bhairabi': 'bahrabise','hetauda':'hetauda sub-metropolitian city', 'sulikot':'barpak sulikot',\n",
    "                    'netrawati':'netrawati dabajon'}\n",
    "    ward_main = set(ward_mapping_data['clean_vdcmun_name'].unique())\n",
    "    nm2       = vdcnum.lower()\n",
    "    ward_main = [nm1.lower() for nm1 in ward_main]\n",
    "    if nm2 in fuzzy_low_ward.keys():\n",
    "        return (fuzzy_low_ward[nm2])\n",
    "    else:\n",
    "        for nm1 in ward_main:\n",
    "            ratio = fuzz.ratio(nm1, nm2)\n",
    "            if ratio > 90:\n",
    "                return (nm1)\n",
    "            \n",
    "# clean vdcmun name\n",
    "def clean_name(name):\n",
    "    change_name = {'netrawati dabajong':'netrawati dabajon', 'tamakoshi': 'likhu tamakoshi'}\n",
    "    if name in change_name.keys():\n",
    "        return change_name[name]\n",
    "    else:\n",
    "        return name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ward mapping and adding lat_long + distance to main file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "district                               = ward_mapping_data.groupby(['district_id', 'district_name']).count().reset_index()[['district_id','district_name']]\n",
    "dist_dict                              = dict(zip(district.district_id, district.district_name))\n",
    "data['district_name']                  = data['district_id'].map(dist_dict)\n",
    "nepal_district['ll_dist_district']     = nepal_district[['lat', 'long']].apply(lambda x : get_distance(x), axis=1)\n",
    "data_lat_long                          = pd.merge(data, nepal_district, on='district_name', how='inner')\n",
    "\n",
    "ward_mapping_data['clean_vdcmun_name'] = ward_mapping_data['vdcmun_name'].apply(lambda x : x.replace(' Rural Municipality', '').replace(' Municipality', '').lower())\n",
    "ward_mapping_data['clean_vdcmun_name'] = ward_mapping_data['clean_vdcmun_name'].apply(lambda x : clean_name(x))\n",
    "ward_mapping_data['district_name']     = ward_mapping_data['district_name'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path          = 'input_data/geoJson/'\n",
    "district_geo  = pygeoj.load(path+\"municipality.geojson\") # to get lat-long\n",
    "coordinates   = []\n",
    "\n",
    "for feature in district_geo:\n",
    "    coordinates.append(feature.geometry.coordinates)\n",
    "    \n",
    "with open(path+\"municipality.topojson\") as f:\n",
    "    d = json.load(f)\n",
    "    \n",
    "geometries    = d['objects']['collection']['geometries']\n",
    "geo_topo_dict = defaultdict(dict)\n",
    "\n",
    "for idx, val in enumerate (geometries):\n",
    "    prop                               = val['properties']\n",
    "    geo_topo_dict[idx]['Name']         = prop['NAME']\n",
    "    geo_topo_dict[idx]['N_ID']         = prop['N_ID']\n",
    "    geo_topo_dict[idx]['Arc']          = val['arcs'] \n",
    "    geo_topo_dict[idx]['F_ID']         = prop['F_ID']\n",
    "    geo_topo_dict[idx]['coordinates']  = coordinates[idx][0]\n",
    "    geo_topo_dict[idx]['district_name']     = prop['DISTRICT'].lower()\n",
    "    \n",
    "geo_topo_df   = pd.DataFrame.from_dict(geo_topo_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_topo_df['distance_to_epicentre'] = geo_topo_df['coordinates'].apply(lambda x : get_avg_distance(x))\n",
    "geo_topo_df['clean_vdcmun_name']     = geo_topo_df['Name'].apply(lambda x :get_fuzzy_string(x) if pd.notnull(x) else x)\n",
    "geo_topo_df['district_name']         = geo_topo_df['district_name'].apply(lambda x : 'sindhupalchok' if x == 'sindhupalchowk' else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create manual coordinates for vdcnum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "'clean_vdcmun_name': ['aamachhodingmo','bahrabise','chishankhu gadhi','dhunibenshi','langtang national park','langtang national park','tarakeshwor', 'likhu tamakoshi'],\n",
    "'coordinates': [[[[85.314914, 28.171318]],],[[[85.915121, 27.800278]],],[[[86.63, 27.32]],], [[[84.916667, 27.866667]],], [[[85.5, 28.25]],],[[[85.5, 28.25]],],\n",
    "           [[[85.303056, 27.786667]],], [[[86.083333, 27.333333]],]],\n",
    "'district_name': ['rasuwa','sindhupalchok','okhaldhunga', 'dhading','nuwakot','sindhupalchok', 'nuwakot','ramechhap']\n",
    "}\n",
    "manual_add = pd.DataFrame(data_dict)\n",
    "manual_add['distance_to_epicentre']    = manual_add['coordinates'].apply(lambda x : get_avg_distance(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging ward map, topology and building_structure files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_topo_df_notnull = geo_topo_df[pd.notnull(geo_topo_df['clean_vdcmun_name'])][['coordinates', 'district_name','distance_to_epicentre', 'clean_vdcmun_name']]\n",
    "geo_topo_manual     = pd.concat([geo_topo_df_notnull, manual_add])\n",
    "ward_topo           = pd.merge(ward_mapping_data, geo_topo_manual, on=['district_name','clean_vdcmun_name'], how='left')\n",
    "data_with_distance  = pd.merge(ward_topo[['distance_to_epicentre', 'ward_id']], data, on=['ward_id'], how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert damage grade to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "damage_dict          ={'Grade 3':2, 'Grade 5':3, 'Grade 2':1, 'Grade 1':0, 'Grade 4':3}\n",
    "data_with_distance['damage_grade_num'] = data_with_distance['damage_grade'].map(damage_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "damage_dict          ={'Grade 3':'Grade 3', 'Grade 5':'Grade 4', 'Grade 2':'Grade 2', 'Grade 1':'Grade 1', 'Grade 4':'Grade 4'}\n",
    "data_with_distance['damage_grade_vis'] = data_with_distance['damage_grade'].map(damage_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# damage_dict          ={'Grade 3':'Medium', 'Grade 5':'High', 'Grade 2':'Low', 'Grade 1':'Low', 'Grade 4':'High'}\n",
    "# data_with_distance['damage_grade_lmh'] = data_with_distance['damage_grade'].map(damage_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_distance.to_csv('clean_data/building_structure_ownership_withdistance_283.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting data into 70 % train and 30 %test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data_with_distance, test_size=0.3, random_state=0, stratify=data_with_distance['damage_grade_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('clean_data/train_withdistance.csv', index=False)\n",
    "test.to_csv('clean_data/test_withdistance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    320456\n",
       "2     95065\n",
       "1     60835\n",
       "0     54909\n",
       "Name: damage_grade_num, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['damage_grade_num'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    137339\n",
       "2     40742\n",
       "1     26072\n",
       "0     23532\n",
       "Name: damage_grade_num, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['damage_grade_num'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
